{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Digit_addition_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3yP36w52Dh6"
      },
      "source": [
        "#PyTorch - MNIST Addition of two digits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8l9L7tY1VBB"
      },
      "source": [
        "Write a neural network that can:\n",
        "\n",
        "take 2 inputs:\n",
        "an image from the MNIST dataset (say 5), and\n",
        "a random number between 0 and 9, (say 7)\n",
        "and gives two outputs:\n",
        "the \"number\" that was represented by the MNIST image (predict 5), and\n",
        "the \"sum\" of this number with the random number and the input image to the network (predict 5 + 7 = 12)\n",
        "\n",
        "\n",
        "\n",
        "you can mix fully connected layers and convolution layers\n",
        "you can use one-hot encoding to represent the random number input as well as the \"summed\" output.\n",
        "\n",
        "Random number (7) can be represented as 0 0 0 0 0 0 0 1 0 0\n",
        "Sum (13) can be represented as:\n",
        "0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
        "0b1101 (remember that 4 digits in binary can at max represent 15, so we may need to go for 5 digits. i.e. 10010\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogybMZdG1ZEq",
        "outputId": "a8ccca5a-93bc-4754-d2e8-b215633dc16b"
      },
      "source": [
        "# Pytorch's tensors are similar to Numpy's ndarrays\n",
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMe0GJ-S2vua"
      },
      "source": [
        "#Import libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEL_Kh-f18bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "327d842e-6b9e-4286-8654-d570793c356b"
      },
      "source": [
        "import torch\n",
        "import torchvision #datasets, models, transforms utils\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torchsummary import summary\n",
        "import random as random\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "# #Evaluate the model in GPU\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)\n",
        "# torch.cuda.set_device(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmnpPU3E2Q3S"
      },
      "source": [
        "#Prepare data set for first 0 - 9 input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onyTfDB-2-pC"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.digit_data = (1,2,3,4,5,6,7,8,9,0)\n",
        "    self.image_train_set = torchvision.datasets.FashionMNIST(root='./data',train=True,download=True,transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.digit_data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.digit_data)\n",
        "  \n",
        "  #Random numberf generation\n",
        "  def getRandomNumber(self,batchsize):\n",
        "    return random.sample(range(0, 10), batchsize)\n",
        "\n",
        "myData = MyDataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnmtQCLg3ets"
      },
      "source": [
        "#compare the actual label with predicted label\n",
        "def get_num_correct(preds, labels):\n",
        "  # return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "  return preds.argmax(dim=1).eq(labels.argmax(dim=1)).sum().item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj9_rZuL7Y1D"
      },
      "source": [
        "#NN Architecture "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJAKUmtRrTpR"
      },
      "source": [
        "\n",
        "class Network1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) \n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "    self.fc1 = nn.Linear(in_features=(12 * 4 * 4), out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out_1 = nn.Linear(in_features=60, out_features=10)\n",
        "\n",
        "    self.fc3 = nn.Linear(in_features=20,out_features=60)\n",
        "    self.fc4 = nn.Linear(in_features=60,out_features=60)\n",
        "    self.out_2 = nn.Linear(in_features=60, out_features=29)\n",
        "\n",
        "  \n",
        "  def forward(self, input_image, input_digit):\n",
        "    # print(\"input size ---> \",input_image.shape,input_digit.shape)\n",
        "    # input layer\n",
        "    x = input_image\n",
        "    d = input_digit\n",
        "\n",
        "    # conv1 layer\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2) # 28 | 24 | 12\n",
        "\n",
        "    # conv2 layer\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2) # 12 | 8 | 4 >> 12x4x4\n",
        "\n",
        "    # reshapre\n",
        "    x = x.reshape(-1, (12 * 4 * 4)) # 1 * 192\n",
        "    # print(\"d shpae before reshape\",d.shape)\n",
        "    d = d.reshape(-1,10) \n",
        "\n",
        "    # fc1 layer\n",
        "    x = self.fc1(x) # 192 | 120\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # fc2 layer\n",
        "    x = self.fc2(x)  #  120 | 60\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # output layer\n",
        "    x = self.out_1(x)   # 60 | 10\n",
        "    # x = F.softmax(x)\n",
        "    # print(\"shape of x and d\",x.shape,d.shape) \n",
        "\n",
        "    x = torch.cat((x, d), dim=1) #  10 +19 | 29\n",
        "\n",
        "    # print(\"shape of x after cat\",x.shape) \n",
        "\n",
        "    # fc3 layer\n",
        "    x = self.fc3(x)    # 11 | 20\n",
        "    x = F.relu(x)\n",
        "\n",
        "    #fc4 layer\n",
        "    x = self.fc4(x)    #  20 | 10\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # output layer\n",
        "    x = self.out_2(x)  #  20 | 2\n",
        "    # x = F.relu(x)\n",
        "    x = F.softmax(x,dim=1)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RxeZVdNnW7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f937504-5e80-42b2-80d5-854f8d6dabf6"
      },
      "source": [
        "network1 = Network1()\n",
        "for name, param in network.named_parameters():\n",
        "  print(name, '\\t\\t', param.shape)\n",
        "\n",
        "batch_size = 10\n",
        "train_loader = torch.utils.data.DataLoader(myData.image_train_set,batch_size=batch_size)\n",
        "# train_loader_digits = torch.utils.data.DataLoader(myData,batch_size=batch_size)\n",
        "optimizer = torch.optim.Adam(network.parameters(),lr=0.001)\n",
        "\n",
        "# summary(network,[(1,28,28),([1,10])])\n",
        "# print(summary(network,[(1,28,28)]))\n",
        "\n",
        "count = 10\n",
        "for epoch in range(10):\n",
        "  \n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "\n",
        "  for batch in train_loader:\n",
        "    images, labels = batch\n",
        "    randomNumTensor = torch.as_tensor(myData.getRandomNumber(batch_size))\n",
        "    # print(randomNumTensor.shape,labels.shape)\n",
        "    # print(randomNumTensor,labels)\n",
        "    # print(addition)\n",
        "    finalLabel = torch.cat((F.one_hot(labels, num_classes=10),F.one_hot(randomNumTensor + labels, num_classes=19)),1).type(torch.float)\n",
        "\n",
        "    preds = network1(images,torch.as_tensor(F.one_hot(randomNumTensor, num_classes=10), dtype=torch.float))\n",
        "    # print(\"label\",labels,torch.as_tensor(F.one_hot(randomNumTensor, num_classes=10), dtype=torch.float))\n",
        "    # print(\"Pred\",preds)\n",
        "    # print(preds[:,0:10].argmax(dim=1))\n",
        "    # print(preds[:,10:].argmax(dim=1))\n",
        "    loss_digit = F.mse_loss(preds,finalLabel)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss_digit.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss =  loss_digit.item()\n",
        "    # print(\"finalLabel,preds\",finalLabel[:10],preds[:10])\n",
        "    total_correct += get_num_correct(preds,finalLabel)\n",
        "  print(\n",
        "      \"epoch\", epoch, \n",
        "      \"total_correct:\", total_correct, \n",
        "      \"loss:\", total_loss\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight \t\t torch.Size([6, 1, 5, 5])\n",
            "conv1.bias \t\t torch.Size([6])\n",
            "conv2.weight \t\t torch.Size([12, 6, 5, 5])\n",
            "conv2.bias \t\t torch.Size([12])\n",
            "fc1.weight \t\t torch.Size([120, 192])\n",
            "fc1.bias \t\t torch.Size([120])\n",
            "fc2.weight \t\t torch.Size([60, 120])\n",
            "fc2.bias \t\t torch.Size([60])\n",
            "out_1.weight \t\t torch.Size([10, 60])\n",
            "out_1.bias \t\t torch.Size([10])\n",
            "fc3.weight \t\t torch.Size([60, 20])\n",
            "fc3.bias \t\t torch.Size([60])\n",
            "fc4.weight \t\t torch.Size([60, 0])\n",
            "fc4.bias \t\t torch.Size([60])\n",
            "out_2.weight \t\t torch.Size([29, 60])\n",
            "out_2.bias \t\t torch.Size([29])\n",
            "epoch 0 total_correct: 1825 loss: 0.06541407108306885\n",
            "epoch 1 total_correct: 1857 loss: 0.06542697548866272\n",
            "epoch 2 total_correct: 1813 loss: 0.06547296047210693\n",
            "epoch 3 total_correct: 1804 loss: 0.06545644253492355\n",
            "epoch 4 total_correct: 1792 loss: 0.06534674763679504\n",
            "epoch 5 total_correct: 1807 loss: 0.06550444662570953\n",
            "epoch 6 total_correct: 1790 loss: 0.06547430902719498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bxPz3LDOB28"
      },
      "source": [
        "\n",
        "# class Network(nn.Module):\n",
        "#   def __init__(self):\n",
        "#     super().__init__()\n",
        "#     self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) \n",
        "#     self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "#     self.fc1 = nn.Linear(in_features=(12 * 4 * 4), out_features=120)\n",
        "#     self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "#     self.out_1 = nn.Linear(in_features=60, out_features=10)\n",
        "\n",
        "#     self.fc3 = nn.Linear(in_features=11,out_features=20)\n",
        "#     self.fc4 = nn.Linear(in_features=20,out_features=20)\n",
        "#     self.out_2 = nn.Linear(in_features=20, out_features=2)\n",
        "\n",
        "  \n",
        "#   def forward(self, input_image, input_digit):\n",
        "#     print(\"input size ---> \",input_image.shape,input_digit.shape)\n",
        "#     # input layer\n",
        "#     x = input_image\n",
        "#     d = input_digit\n",
        "\n",
        "#     # conv1 layer\n",
        "#     x = self.conv1(x)\n",
        "#     x = F.relu(x)\n",
        "#     x = F.max_pool2d(x, kernel_size=2, stride=2) # 28 | 24 | 12\n",
        "\n",
        "#     # conv2 layer\n",
        "#     x = self.conv2(x)\n",
        "#     x = F.relu(x)\n",
        "#     x = F.max_pool2d(x, kernel_size=2, stride=2) # 12 | 8 | 4 >> 12x4x4\n",
        "\n",
        "#     # reshapre\n",
        "#     x = x.reshape(-1, (12 * 4 * 4)) # 1 * 192\n",
        "#     # print(\"d shpae before reshape\",d.shape)\n",
        "#     d = d.reshape(-1,1) \n",
        "\n",
        "#     # fc1 layer\n",
        "#     x = self.fc1(x) # 192 | 120\n",
        "#     x = F.relu(x)\n",
        "\n",
        "#     # fc2 layer\n",
        "#     x = self.fc2(x)  #  120 | 60\n",
        "#     x = F.relu(x)\n",
        "\n",
        "#     # output layer\n",
        "#     x = self.out_1(x)   # 60 | 10\n",
        "#     # x = F.softmax(x)\n",
        "#     # print(\"shape of x and d\",x.shape,d.shape) \n",
        "\n",
        "#     x = torch.cat((x, d), dim=1) #  10 +1 | 11\n",
        "\n",
        "#     # print(\"shape of x after cat\",x.shape) \n",
        "\n",
        "#     # fc3 layer\n",
        "#     x = self.fc3(x)    # 11 | 20\n",
        "#     x = F.relu(x)\n",
        "\n",
        "#     #fc4 layer\n",
        "#     x = self.fc4(x)    #  20 | 10\n",
        "#     x = F.relu(x)\n",
        "\n",
        "#     # output layer\n",
        "#     x = self.out_2(x)  #  20 | 2\n",
        "#     x = F.relu(x)\n",
        "#     return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO4UEzxmgjFe"
      },
      "source": [
        "# network = Network()\n",
        "# for name, param in network.named_parameters():\n",
        "#   print(name, '\\t\\t', param.shape)\n",
        "\n",
        "# batch_size = 10\n",
        "# train_loader = torch.utils.data.DataLoader(myData.image_train_set,batch_size=batch_size)\n",
        "# # train_loader_digits = torch.utils.data.DataLoader(myData,batch_size=batch_size)\n",
        "# optimizer = torch.optim.Adam(network.parameters(),lr=0.001)\n",
        "\n",
        "# # summary(network,[(1,28,28),([1,10])])\n",
        "# # print(summary(network,[(1,28,28)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2L-Kyu90zW1"
      },
      "source": [
        "\n",
        "# count = 10\n",
        "# for epoch in range(1):\n",
        "  \n",
        "#   total_loss = 0\n",
        "#   total_correct = 0\n",
        "\n",
        "#   for batch in train_loader:\n",
        "#     images, labels = batch\n",
        "#     randomNumTensor = torch.as_tensor(myData.getRandomNumber(batch_size)).type(torch.float)\n",
        "#     # print(randomNumTensor.shape,labels.shape)\n",
        "#     addition = randomNumTensor+labels\n",
        "#     # print(randomNumTensor,labels)\n",
        "#     # print(addition)\n",
        "#     Sumlabels = torch.cat((labels,addition),0)\n",
        "#     # print(\"Sumlabels before reshape\",Sumlabels)\n",
        "#     Sumlabels = Sumlabels.reshape(10,2)\n",
        "#     # print(\"Sumlabels after reshape\",Sumlabels)\n",
        "#     preds = network(images,randomNumTensor)\n",
        "#     # print(\"Sumlabels.shape,preds.shape\",Sumlabels.shape,preds.shape)\n",
        "#     print(\"label\",labels,randomNumTensor,addition)\n",
        "#     print(\"Pred\",preds)\n",
        "#     loss_digit = F.mse_loss(preds,Sumlabels)\n",
        "\n",
        "#     optimizer.zero_grad()\n",
        "#     loss_digit.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "#     total_loss =  loss_digit.item()\n",
        "#     total_correct += get_num_correct(preds,labels)\n",
        "#   print(\n",
        "#       \"epoch\", epoch, \n",
        "#       \"total_correct:\", total_correct, \n",
        "#       \"loss:\", total_loss\n",
        "#   )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}